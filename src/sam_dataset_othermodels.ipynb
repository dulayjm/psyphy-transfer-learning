{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abaa9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid_distortion.py\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from scipy.interpolate import griddata\n",
    "# import sys\n",
    "\n",
    "# INTERPOLATION = {\n",
    "#     \"linear\": cv2.INTER_LINEAR,\n",
    "#     \"cubic\": cv2.INTER_CUBIC\n",
    "# }\n",
    "\n",
    "# def warp_image(img, random_state=None, **kwargs):\n",
    "#     if random_state is None:\n",
    "#         random_state = np.random.RandomState()\n",
    "\n",
    "#     w_mesh_interval = kwargs.get('w_mesh_interval', 25)\n",
    "#     w_mesh_std = kwargs.get('w_mesh_std', 3.0)\n",
    "\n",
    "#     h_mesh_interval = kwargs.get('h_mesh_interval', 25)\n",
    "#     h_mesh_std = kwargs.get('h_mesh_std', 3.0)\n",
    "\n",
    "#     interpolation_method = kwargs.get('interpolation', 'linear')\n",
    "\n",
    "#     h, w = img.shape[:2]\n",
    "\n",
    "#     if kwargs.get(\"fit_interval_to_image\", True):\n",
    "#         # Change interval so it fits the image size\n",
    "#         w_ratio = w / float(w_mesh_interval)\n",
    "#         h_ratio = h / float(h_mesh_interval)\n",
    "\n",
    "#         w_ratio = max(1, round(w_ratio))\n",
    "#         h_ratio = max(1, round(h_ratio))\n",
    "\n",
    "#         w_mesh_interval = w / w_ratio\n",
    "#         h_mesh_interval = h / h_ratio\n",
    "#         ############################################\n",
    "\n",
    "#     # Get control points\n",
    "#     source = np.mgrid[0:h+h_mesh_interval:h_mesh_interval, 0:w+w_mesh_interval:w_mesh_interval]\n",
    "#     source = source.transpose(1,2,0).reshape(-1,2)\n",
    "\n",
    "#     if kwargs.get(\"draw_grid_lines\", False):\n",
    "#         if len(img.shape) == 2:\n",
    "#             color = 0\n",
    "#         else:\n",
    "#             color = np.array([0,0,255])\n",
    "#         for s in source:\n",
    "#             img[int(s[0]):int(s[0])+1,:] = color\n",
    "#             img[:,int(s[1]):int(s[1])+1] = color\n",
    "\n",
    "#     # Perturb source control points\n",
    "#     destination = source.copy()\n",
    "#     source_shape = source.shape[:1]\n",
    "#     destination[:,0] = destination[:,0] + random_state.normal(0.0, h_mesh_std, size=source_shape)\n",
    "#     destination[:,1] = destination[:,1] + random_state.normal(0.0, w_mesh_std, size=source_shape)\n",
    "\n",
    "#     # Warp image\n",
    "#     grid_x, grid_y = np.mgrid[0:h, 0:w]\n",
    "#     grid_z = griddata(destination, source, (grid_x, grid_y), method=interpolation_method).astype(np.float32)\n",
    "#     map_x = grid_z[:,:,1]\n",
    "#     map_y = grid_z[:,:,0]\n",
    "#     warped = cv2.remap(img, map_x, map_y, INTERPOLATION[interpolation_method], borderValue=(255,255,255))\n",
    "\n",
    "#     return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa6184d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install python-string-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "730f238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c98035ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_rates.py\n",
    "\n",
    "import editdistance\n",
    "\n",
    "def error_cer(r, h):\n",
    "    #Remove any double or trailing\n",
    "    r = u' '.join(r.split())\n",
    "    h = u' '.join(h.split())\n",
    "\n",
    "    return error_err(r, h)\n",
    "\n",
    "def error_err(r, h):\n",
    "    dis = editdistance.eval(r, h)\n",
    "    if len(r) == 0.0:\n",
    "        return len(h)\n",
    "\n",
    "    return float(dis) / float(len(r))\n",
    "\n",
    "def error_wer(r, h):\n",
    "    r = r.split()\n",
    "    h = h.split()\n",
    "\n",
    "    return error_err(r,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8005963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_char_set(char_set_path):\n",
    "    with open(char_set_path) as f:\n",
    "        char_set = json.load(f)\n",
    "\n",
    "    idx_to_char = {}\n",
    "    for k,v in char_set['idx_to_char'].items():        \n",
    "        idx_to_char[int(k)] = v\n",
    "\n",
    "    return idx_to_char, char_set['char_to_idx']\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     character_set_path = sys.argv[-1]\n",
    "#     out_char_to_idx = {}\n",
    "#     out_idx_to_char = {}\n",
    "#     char_freq = defaultdict(int)\n",
    "#     for i in range(1, len(sys.argv)-1):\n",
    "#         data_file = sys.argv[i]\n",
    "#         with open(data_file) as f:\n",
    "#             data = json.load(f)\n",
    "\n",
    "#         cnt = 1 # this is important that this starts at 1 not 0\n",
    "#         for data_item in data:\n",
    "#             for c in data_item.get('gt', \"\"):\n",
    "#                 if c not in out_char_to_idx:\n",
    "#                     out_char_to_idx[c] = cnt\n",
    "#                     out_idx_to_char[cnt] = c\n",
    "#                     cnt += 1\n",
    "#                 char_freq[c] += 1\n",
    "\n",
    "#     out_char_to_idx2 = {}\n",
    "#     out_idx_to_char2 = {}\n",
    "\n",
    "#     for i, c in enumerate(sorted(out_char_to_idx.keys())):\n",
    "#         out_char_to_idx2[c] = i+1\n",
    "#         out_idx_to_char2[i+1] = c\n",
    "\n",
    "#     output_data = {\n",
    "#         \"char_to_idx\": out_char_to_idx2,\n",
    "#         \"idx_to_char\": out_idx_to_char2\n",
    "#     }\n",
    "\n",
    "#     for k,v in sorted(char_freq.iteritems(), key=lambda x: x[1]):\n",
    "#         print(k, v)\n",
    "\n",
    "#     print(\"Size:\", len(output_data['char_to_idx']))\n",
    "\n",
    "#     with open(character_set_path, 'w') as outfile:\n",
    "#         json.dump(output_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed574c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def str2label(value, characterToIndex={}, unknown_index=None):\n",
    "    if unknown_index is None:\n",
    "        unknown_index = len(characterToIndex)\n",
    "\n",
    "    label = []\n",
    "    for v in value:\n",
    "        # print(v)\n",
    "        if v not in characterToIndex:\n",
    "            continue\n",
    "        label.append(characterToIndex[v])\n",
    "    return np.array(label, np.uint32)\n",
    "\n",
    "def label2input(value, num_of_inputs, char_break_interval):\n",
    "    idx1 = len(value) * (char_break_interval + 1) + char_break_interval\n",
    "    idx2 = num_of_inputs + 1\n",
    "    print(idx1)\n",
    "    print(idx2)\n",
    "    input_data = [[0 for i in range(idx2)] for j in range(idx1)]\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(char_break_interval):\n",
    "        input_data[cnt][idx2-1] = 1\n",
    "        cnt += 1\n",
    "\n",
    "    for i in range(len(value)):\n",
    "        if value[i] == 0:\n",
    "            input_data[cnt][idx2-1] = 1\n",
    "        else:\n",
    "            input_data[cnt][value[i]-1] = 1\n",
    "        cnt += 1\n",
    "\n",
    "        for i in range(char_break_interval):\n",
    "            input_data[cnt][idx2-1] = 1\n",
    "            cnt += 1\n",
    "\n",
    "    return np.array(input_data)\n",
    "\n",
    "def label2str(label, indexToCharacter, asRaw, spaceChar = \"~\"):\n",
    "    string = u\"\"\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 0:\n",
    "            if asRaw:\n",
    "                string += spaceChar\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            val = label[i]\n",
    "            string += indexToCharacter[val]\n",
    "    return string\n",
    "\n",
    "def naive_decode(output):\n",
    "    rawPredData = np.argmax(output, axis=1)\n",
    "    predData = []\n",
    "    for i in range(len(output)):\n",
    "        if rawPredData[i] != 0 and not ( i > 0 and rawPredData[i] == rawPredData[i-1] ):\n",
    "            predData.append(rawPredData[i])\n",
    "    return predData, list(rawPredData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d39c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "# from collections import defaultdict\n",
    "# import os\n",
    "# # import cv2\n",
    "# from PIL import Image\n",
    "\n",
    "# import numpy as np\n",
    "# # fuck is this even cht ecode \n",
    "\n",
    "\n",
    "# import random\n",
    "\n",
    "\n",
    "# PADDING_CONSTANT = 255\n",
    "\n",
    "# coeff = 1000\n",
    "\n",
    "# def batch_collate(batch):\n",
    "#     global coeff\n",
    "#     batch = [b for b in batch if b is not None]\n",
    "# #     #These all should be the same size or error\n",
    "    \n",
    "    \n",
    "# #     print('the entire fucking batch is ', batch)\n",
    "# #     print('len of the images array in the batch is', len(batch[0]))\n",
    "# #     1/0\n",
    "\n",
    "\n",
    "\n",
    "# #     print('in collate, the batch shape is ', len(batch))\n",
    "# #     print('in collate, the batch 0 is ', len(batch[0]))\n",
    "# #     print('in collate, the batch 0 is ', batch[0])\n",
    "\n",
    "# #     print('type of bach is ', type(batch))\n",
    "# #     print('type of bach is ', type(batch[0]))\n",
    "# #     print(batch)\n",
    "\n",
    "\n",
    "# #     print([b['line_img'].shape[0] for b in batch])\n",
    "\n",
    "# #     print([b['line_img'].shape[2] for b in batch])\n",
    "\n",
    "\n",
    "# #     print('batch shape 2 is', batch.shape[2])\n",
    "\n",
    "# # \n",
    "#     # are rts's just a directory ?\n",
    "# #     1/0/\n",
    "# #     assert len(set([b['line_img'].shape[0] for b in batch])) == 1\n",
    "# #     assert len(set([b['line_img'].shape[2] for b in batch])) == 1\n",
    "\n",
    "#     dim0 = batch[0]['line_img'].shape[0]\n",
    "#     dim1 = max([b['line_img'].shape[1] for b in batch])\n",
    "#     dim1 = dim1 + (dim0 - (dim1 % dim0))\n",
    "#     # so it messes up here?\n",
    "#     print('the object shape we are dealing with is', batch[0]['line_img'].shape)\n",
    "    \n",
    "#     dim2 = batch[0]['line_img'].shape[2]\n",
    "\n",
    "#     all_labels = []\n",
    "#     label_lengths = []\n",
    "#     psychs = []\n",
    "    \n",
    "\n",
    "#     input_batch = np.full((len(batch), dim0, dim1, dim2), PADDING_CONSTANT).astype(np.float32)\n",
    "#     for i in range(len(batch)):\n",
    "#         b_img = batch[i]['line_img']\n",
    "#         input_batch[i,:,:b_img.shape[1],:] = b_img\n",
    "#         l = batch[i]['gt_label']\n",
    "#         psych = batch[i]['psych']\n",
    "#         all_labels.append(l)\n",
    "#         label_lengths.append(len(l))\n",
    "#         if psych is not None:\n",
    "#             # print(psych)\n",
    "#             # print(((200-psych)/len(l)))\n",
    "#             # print(\"-----------\")\n",
    "#             psych = 200-psych\n",
    "#             if psych < 0:\n",
    "#                 print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#                 print((psych) / len(l))\n",
    "#             psychs.append((psych/len(l))*coeff)\n",
    "#         else:\n",
    "#             psychs.append(0)\n",
    "#     all_labels = np.concatenate(all_labels)\n",
    "#     label_lengths = np.array(label_lengths)\n",
    "\n",
    "#     line_imgs = input_batch.transpose([0,3,1,2])\n",
    "#     line_imgs = torch.from_numpy(line_imgs)\n",
    "#     labels = torch.from_numpy(all_labels.astype(np.int32))\n",
    "#     label_lengths = torch.from_numpy(label_lengths.astype(np.int32))\n",
    "\n",
    "#     return {\n",
    "#         \"line_imgs\": line_imgs,\n",
    "#         \"labels\": labels,\n",
    "#         \"psychs\": psychs,\n",
    "#         \"label_lengths\": label_lengths,\n",
    "#         \"gt\": [b['gt'] for b in batch]\n",
    "#     }\n",
    "\n",
    "# class HwDataset(Dataset):\n",
    "#     def __init__(self, \n",
    "#                  json_path, \n",
    "#                  char_to_idx, \n",
    "#                  img_height=32, \n",
    "#                  root_path=\".\",\n",
    "#                  augmentation=False,\n",
    "#                  psychPath=\"./data/\", # needs to exist you fuck ass\n",
    "#                  randomW=False,\n",
    "#                  coef=1000):\n",
    "        \n",
    "#         global coeff\n",
    "#         with open(json_path) as f:\n",
    "#             data = json.load(f)\n",
    "            \n",
    "#             # but we now need to loop through alll the directories\n",
    "#             # so load root_dir (data) her \n",
    "            \n",
    "            \n",
    "#         self.root_path = root_path\n",
    "#         self.img_height = img_height\n",
    "#         self.char_to_idx = char_to_idx\n",
    "#         self.data = data\n",
    "#         self.psychPath = psychPath\n",
    "#         self.augmentation = augmentation\n",
    "#         self.randomWeights = None\n",
    "#         coeff = coef\n",
    "#         if randomW:\n",
    "#             self.randomWeights = np.random.randint(50, 200, len(self.data))\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "#         # and on __getitem__ \n",
    "#         # do the json loading. I think.\n",
    "        \n",
    "#         item = self.data[idx]\n",
    "#         # just worry about resizing after\n",
    "#         # i think those cv2 augmentations just make it a square ...\n",
    "#         img = np.array(Image.open(os.path.join(self.root_path, item['image_path'])))\n",
    "        \n",
    "# #         img = cv2.imread(os.path.join(self.root_path, item['image_path']))\n",
    "                       \n",
    "#         if self.randomWeights is None:\n",
    "#             try:\n",
    "#                 # replace \"magic number path\"\n",
    "#                 # print(item['image_path'].split('/')[-1].split('.')[0])\n",
    "#                 mangled_string = self.psychPath+item['image_path'].split('/')[-1].split('.')[0]+\"Time.json\"\n",
    "#                 print('mangled string is', mangled_string)\n",
    "                \n",
    "#                 with open(self.psychPath+item['image_path'].split('/')[-1].split('.')[0]+\"Time.json\") as f:\n",
    "#                     psych = json.load(f)\n",
    "                    \n",
    "                    \n",
    "#                 print(\"psych is after that loaddddd\", psych)\n",
    "#             except:\n",
    "#                 psych = None\n",
    "#         else:\n",
    "#             print(\"WARNING!!! RANDOM PSYCHOMETRIC WEIGHTS ARE BEING USED\")\n",
    "#             psych = self.randomWeights[idx]\n",
    "#             # print psych\n",
    "\n",
    "#         if img is None:\n",
    "#             print(\"Warning: image is None:\", os.path.join(self.root_path, item['image_path']))\n",
    "#             return None\n",
    "\n",
    "# #         percent = float(self.img_height) / img.shape[0]\n",
    "# #         print('percent is', percent)\n",
    "                       \n",
    "                       \n",
    "# #         img = cv2.resize(img, (0,0), fx=percent, fy=percent, interpolation = cv2.INTER_CUBIC)                       \n",
    "                       \n",
    "# #         if self.augmentation:\n",
    "# #             img = grid_distortion.warp_image(img, h_mesh_std=5, w_mesh_std=10)\n",
    "\n",
    "#         img = img.astype(np.float32)\n",
    "#         img = img / 128.0 - 1.0\n",
    "\n",
    "#         gt = item['gt']\n",
    "#         gt_label = str2label(gt, self.char_to_idx)\n",
    "\n",
    "#         print('fuckign here')\n",
    "#         print(type(img))\n",
    "#         print(type(gt_label))\n",
    "#         print(type(psych))\n",
    "#         print(type(gt))\n",
    "#         print(\"FLKSHJLKDFJSDLFJLFSDKJLKDSF\")\n",
    "#         print(img)\n",
    "#         print(gt_label)\n",
    "#         print(psych)\n",
    "#         print(gt)\n",
    "\n",
    "        \n",
    "# #         1/0\n",
    "\n",
    "#         # whyyyy is this reutrned as a list\n",
    "        \n",
    "#         ret_dict = {\n",
    "#             \"line_img\": img,\n",
    "#             \"gt_label\": gt_label,\n",
    "#             \"psych\": psych,\n",
    "#             \"gt\": gt,\n",
    "#         }\n",
    "        \n",
    "#         print('the type of fucking ret_dict is', type(ret_dict))\n",
    "        \n",
    "#         return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe8e79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fresh copy of the code \n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import string_utils\n",
    "\n",
    "# import grid_distortiongrid_distortion\n",
    "\n",
    "PADDING_CONSTANT = 255\n",
    "\n",
    "coeff = 1000\n",
    "\n",
    "\n",
    "def batch_collate(batch):\n",
    "    global coeff\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    #These all should be the same size or error\n",
    "    assert len(set([b['line_img'].shape[0] for b in batch])) == 1\n",
    "    assert len(set([b['line_img'].shape[2] for b in batch])) == 1\n",
    "\n",
    "    dim0 = batch[0]['line_img'].shape[0]\n",
    "    dim1 = max([b['line_img'].shape[1] for b in batch])\n",
    "    dim1 = dim1 + (dim0 - (dim1 % dim0))\n",
    "    dim2 = batch[0]['line_img'].shape[2]\n",
    "\n",
    "    all_labels = []\n",
    "    label_lengths = []\n",
    "    psychs = []\n",
    "    \n",
    "\n",
    "    input_batch = np.full((len(batch), dim0, dim1, dim2), PADDING_CONSTANT).astype(np.float32)\n",
    "    for i in range(len(batch)):\n",
    "        b_img = batch[i]['line_img']\n",
    "        input_batch[i,:,:b_img.shape[1],:] = b_img\n",
    "        l = batch[i]['gt_label']\n",
    "        psych = batch[i]['psych']\n",
    "        all_labels.append(l)\n",
    "        label_lengths.append(len(l))\n",
    "        if psych is not None:\n",
    "            # print(psych)\n",
    "            # print(((200-psych)/len(l)))\n",
    "            # print(\"-----------\")\n",
    "            psych = 200-psych\n",
    "            if psych < 0:\n",
    "                print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                print((psych) / len(l))\n",
    "            psychs.append((psych/len(l))*coeff)\n",
    "        else:\n",
    "            psychs.append(0)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    label_lengths = np.array(label_lengths)\n",
    "\n",
    "    line_imgs = input_batch.transpose([0,3,1,2])\n",
    "    line_imgs = torch.from_numpy(line_imgs)\n",
    "    labels = torch.from_numpy(all_labels.astype(np.int32))\n",
    "    label_lengths = torch.from_numpy(label_lengths.astype(np.int32))\n",
    "\n",
    "    # psychs needs to be a tensor?\n",
    "    \n",
    "    return {\n",
    "        \"line_imgs\": line_imgs,\n",
    "        \"labels\": labels,\n",
    "        \"psychs\": psychs,\n",
    "        \"label_lengths\": label_lengths,\n",
    "        \"gt\": [b['gt'] for b in batch]\n",
    "    }\n",
    "\n",
    "class HwDataset(Dataset):\n",
    "    def __init__(self, json_path, char_to_idx, img_height=32, root_path=\".\", augmentation=False, psychPath=\"\", randomW=False, coef=1000):\n",
    "        global coeff\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "        self.root_path = root_path\n",
    "        self.img_height = img_height\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.data = data\n",
    "        self.psychPath = psychPath\n",
    "        self.augmentation = augmentation\n",
    "        self.randomWeights = None\n",
    "        coeff = coef\n",
    "        if randomW:\n",
    "            self.randomWeights = np.random.randint(50, 200, len(self.data))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(os.path.join(self.root_path, item['image_path']))\n",
    "        if self.randomWeights is None:\n",
    "            try:\n",
    "                # replace \"magic number path\"\n",
    "                # print(item['image_path'].split('/')[-1].split('.')[0])\n",
    "                with open(self.psychPath+item['image_path'].split('/')[-1].split('.')[0]+\"Time.json\") as f:\n",
    "                    psych = json.load(f)\n",
    "            except:\n",
    "                psych = None\n",
    "        else:\n",
    "            print(\"WARNING!!! RANDOM PSYCHOMETRIC WEIGHTS ARE BEING USED\")\n",
    "            psych = self.randomWeights[idx]\n",
    "            # print psych\n",
    "\n",
    "        if img is None:\n",
    "            print(\"Warning: image is None:\", os.path.join(self.root_path, item['image_path']))\n",
    "            return None\n",
    "\n",
    "\n",
    "        percent = float(self.img_height) / img.shape[0]\n",
    "        img = cv2.resize(img, (0,0), fx=percent, fy=percent, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        \n",
    "        # no need to augment crazy \n",
    "        \n",
    "#         if self.augmentation:\n",
    "#             img = warp_image(img, h_mesh_std=5, w_mesh_std=10)\n",
    "\n",
    "        img = img.astype(np.float32)\n",
    "        img = img / 128.0 - 1.0\n",
    "\n",
    "        gt = item['gt']\n",
    "        gt_label = str2label(gt, self.char_to_idx)\n",
    "\n",
    "        return {\n",
    "            \"line_img\": img,\n",
    "            \"gt_label\": gt_label,\n",
    "            \"psych\":psych,\n",
    "            \"gt\": gt\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6fd987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf3ea9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True, dropout=0.5, num_layers=2)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.reshape(T * b, h)\n",
    "\n",
    "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
    "        output = output.reshape(T, b, -1)\n",
    "\n",
    "        return output\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, cnnOutSize, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = nc if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
    "        convRelu(6, True)  # 512x1x16\n",
    "\n",
    "        self.cnn = cnn\n",
    "        self.rnn = BidirectionalLSTM(cnnOutSize, nh, nclass)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv = self.cnn(input)\n",
    "        b, c, h, w = conv.size()\n",
    "        conv = conv.reshape(b, -1, w)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "\n",
    "\n",
    "        return output\n",
    "\n",
    "def create_model(config):\n",
    "    crnn = CRNN(config['cnn_out_size'], config['num_of_channels'], config['num_of_outputs'], 512)\n",
    "    return crnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "046f7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyResnet(nn.Module):\n",
    "#     def __init__(): \n",
    "#         super.__init__(MyResnet,self)\n",
    "        \n",
    "#         self.backbone = resnet50(pretrained=True).to(device)\n",
    "#         self.backbone.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e43ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we incorporate our other code into this one w/ the data uploaded \n",
    "\n",
    "# use their train routine, but with your model training script stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "357a1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# their training routine\n",
    "import json\n",
    "# import character_set\n",
    "import sys\n",
    "# import crnn\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "# from warpctc_pytorch import CTCLoss\n",
    "# import error_rates\n",
    "# import string_utils\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# their config \n",
    "config = {\n",
    "    \"training_set_path\" : \"/afs/crc.nd.edu/group/cvrl/scratch_31/sgrieggs/IAM_aachen/train.json\",\n",
    "#     \"training_set_path\": \"prepare_font_data/training.json\",\n",
    "    \"validation_set_path\": \"/afs/crc.nd.edu/group/cvrl/scratch_31/sgrieggs/IAM_aachen/val.json\",\n",
    "    \"image_root_directory\": \"/afs/crc.nd.edu/group/cvrl/scratch_31/sgrieggs/IAM_aachen/\",\n",
    "    \"model_save_path\": \"sam_data.pt\",\n",
    "    \"network\": {\n",
    "        \"input_height\": 60,\n",
    "        \"cnn_out_size\": 1024,\n",
    "        \"learning_rate\": 1e-4\n",
    "    },\n",
    "    \"character_set_path\": \"char_set.json\"\n",
    "}\n",
    "# but something to do with this later um \n",
    "\n",
    "# # but what character set path to use\n",
    "# idx_to_char, char_to_idx = load_char_set(config['character_set_path'])\n",
    "\n",
    "# # we don't want that font traing stuff\n",
    "# # we want the data that's actually in our path \n",
    "# # but our labels are a set form a char file\n",
    "# # and our rts are from the list of rt files per label, no?\n",
    "\n",
    "\n",
    "# train_dataset = HwDataset(config['training_set_path'], char_to_idx, img_height=config['network']['input_height'], root_path=config['image_root_directory'], augmentation=True)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=0, collate_fn=batch_collate)\n",
    "\n",
    "# test_dataset = HwDataset(config['validation_set_path'], char_to_idx, img_height=config['network']['input_height'], root_path=config['image_root_directory'])\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0, collate_fn=batch_collate)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print('device is', device)\n",
    "\n",
    "# model = resnet50(pretrained=True).to(device)\n",
    "# model.fc = nn.Linear(2048, 295)\n",
    "# model.train()\n",
    "\n",
    "# # model = create_model({\n",
    "# #     'cnn_out_size': config['network']['cnn_out_size'],\n",
    "# #     'num_of_channels': 3,\n",
    "# #     'num_of_outputs': len(idx_to_char)+1\n",
    "# # })\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     model.to(device)\n",
    "#     dtype = torch.cuda.FloatTensor\n",
    "#     print(\"Using GPU\")\n",
    "# else:\n",
    "#     dtype = torch.FloatTensor\n",
    "#     print(\"No GPU detected\")\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=config['network']['learning_rate'])\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# lowest_loss = float('inf')\n",
    "\n",
    "\n",
    "# print('sanity  is', train_dataloader)\n",
    "# print(len(train_dataloader))\n",
    "# print(len(train_dataset))\n",
    "\n",
    "# # print('model is ', model)\n",
    "\n",
    "\n",
    "# # dataiter = iter(train_dataloader)\n",
    "# # batch = next(dataiter)\n",
    "\n",
    "\n",
    "# # 1/0\n",
    "# # \n",
    "# for epoch in range(1000):\n",
    "#     sum_loss = 0.0\n",
    "#     steps = 0.0\n",
    "#     for x in train_dataloader:\n",
    "#         # then we care about how their dataset __getitem__\n",
    "# #         return {\n",
    "# #             \"line_imgs\": line_imgs,\n",
    "# #             \"labels\": labels,\n",
    "# #             \"psychs\": psychs,\n",
    "# #             \"label_lengths\": label_lengths,\n",
    "# #             \"gt\": [b['gt'] for b in batch]\n",
    "# #         }\n",
    "\n",
    "#         # so we could do some dataloader stuff, but this is what we need to change here \n",
    "#         # psychs needs to be a torch tensor from the batch stuff \n",
    "        \n",
    "#         psychs = x['psychs']\n",
    "#         if isinstance(psychs, list):\n",
    "#             psychs = torch.LongTensor(psychs) \n",
    "#         psychs = Variable(psychs, requires_grad=False)\n",
    "        \n",
    "# #         labels = torch.FloatTensor(labels)\n",
    "# #         print('gt should be', x['gt'])\n",
    "        \n",
    "# #         gt = x['gt']\n",
    "# #         if isinstance(gt, list):\n",
    "# #             gt = torch.tensor(gt)\n",
    "# #         gt = Variable(gt, requires_grad=False)\n",
    "    \n",
    "#         line_imgs = Variable(x['line_imgs'].type(dtype), requires_grad=False)\n",
    "#         labels =  Variable(x['labels'], requires_grad=False)\n",
    "#         label_lengths = Variable(x['label_lengths'], requires_grad=False)\n",
    "\n",
    "#         preds = model(line_imgs)\n",
    "#         preds_size = Variable(torch.LongTensor([preds.size(0)] * preds.size(1)))\n",
    "#         preds = preds.permute(1,0)\n",
    "        \n",
    "#         print('preds shape is', preds.shape)\n",
    "        \n",
    "# #         output_batch = preds.permute(1,0,2)\n",
    "# #         out = output_batch.data.cpu().numpy()\n",
    "\n",
    "# #         loss = criterion(preds, labels, preds_size, label_lengths)\n",
    "#         labels = torch.LongTensor(labels)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         print('here')\n",
    "#         print(line_imgs.shape)\n",
    "#         print(preds.dtype)\n",
    "#         print(labels.dtype)\n",
    "\n",
    "#         loss = criterion(preds, labels)\n",
    "\n",
    "#         # or \n",
    "# #         loss = RtPsychCrossEntropyLoss(outputs, labels, psych_tensor).to(device)\n",
    "            \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         #if i == 0:\n",
    "#         #    for i in xrange(out.shape[0]):\n",
    "#         #        pred, pred_raw = string_utils.naive_decode(out[i,...])\n",
    "#         #        pred_str = string_utils.label2str(pred_raw, idx_to_char, True)\n",
    "#         #        print(pred_str)\n",
    "\n",
    "#         for j in range(out.shape[0]):\n",
    "#             logits = out[j,...]\n",
    "#             pred, raw_pred = naive_decode(logits)\n",
    "#             pred_str = label2str(pred, idx_to_char, False)\n",
    "#             gt_str = x['gt'][j]\n",
    "#             cer = error_rates.cer(gt_str, pred_str)\n",
    "#             sum_loss += cer\n",
    "#             steps += 1\n",
    "\n",
    "#     print(\"Training CER\", sum_loss / steps)\n",
    "\n",
    "#     sum_loss = 0.0\n",
    "#     steps = 0.0\n",
    "#     model.eval()\n",
    "#     for x in test_dataloader:\n",
    "#         line_imgs = Variable(x['line_imgs'].type(dtype), requires_grad=False, volatile=True)\n",
    "#         labels =  Variable(x['labels'], requires_grad=False, volatile=True)\n",
    "#         label_lengths = Variable(x['label_lengths'], requires_grad=False, volatile=True)\n",
    "\n",
    "#         preds = model(line_imgs).cpu()\n",
    "\n",
    "#         output_batch = preds.permute(1,0,2)\n",
    "#         out = output_batch.data.cpu().numpy()\n",
    "\n",
    "#         for i, gt_line in enumerate(x['gt']):\n",
    "#             logits = out[i,...]\n",
    "#             pred, raw_pred = naive_decode(logits)\n",
    "#             pred_str = label2str(pred, idx_to_char, False)\n",
    "#             cer_ = cer(gt_line, pred_str)\n",
    "#             sum_loss += cer_\n",
    "#             steps += 1\n",
    "\n",
    "#     print(\"Test CER\", sum_loss / steps)\n",
    "\n",
    "#     if lowest_loss > sum_loss/steps:\n",
    "#         lowest_loss = sum_loss/steps\n",
    "#         print(\"Saving Best\")\n",
    "#         dirname = os.path.dirname(config['model_save_path'])\n",
    "#         if len(dirname) > 0 and not os.path.exists(dirname):\n",
    "#             os.makedirs(dirname)\n",
    "\n",
    "#         torch.save(model.state_dict(), os.path.join(config['model_save_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc40d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import character_set\n",
    "# import sys\n",
    "# # import hwpsych_dataset\n",
    "# # from hwpsych_dataset import HwDataset\n",
    "# # import urnn, urnn2, urnn_window\n",
    "# # import crnn, crnn2\n",
    "# # import unet_hwr as unet\n",
    "# import os\n",
    "# import torch\n",
    "# from torch.utils import data\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.autograd import Variable\n",
    "# # import error_rates\n",
    "# # import string_utils\n",
    "# import time\n",
    "# from  torch.nn.modules.loss import CTCLoss\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# psychPath = \"./data/\"\n",
    "\n",
    "\n",
    "# class PsychCTC(torch.nn.Module):\n",
    "#     def __init__(self,idx_to_char, char_to_idx, verbose = False):\n",
    "#         super(PsychCTC, self).__init__()\n",
    "#         self.citerion = CTCLoss(reduction = 'none', zero_infinity=True)\n",
    "#         self.idx_to_char = idx_to_char\n",
    "#         self.char_to_idx = char_to_idx\n",
    "#         self.verbose = verbose\n",
    "\n",
    "\n",
    "#     def forward(self, preds, labels, preds_size, label_lengths, psych):\n",
    "#         # print(len(self.char_to_idx))\n",
    "#         # might need preds_size to be 8\n",
    "#         print('in the loss')        \n",
    "#         print('preds', preds.shape)\n",
    "#         print('labels', labels.shape)\n",
    "\n",
    "        \n",
    "#         print('pred_size', preds_size.shape)\n",
    "#         print('label_lenghts', label_lengths.shape)\n",
    "        \n",
    "#         loss = self.citerion(preds, labels, preds_size, label_lengths).cuda()\n",
    "#         index = 0\n",
    "#         # lbl = labels.detach().cpu().numpy()\n",
    "#         lbl = labels.data.cpu().numpy()\n",
    "#         lbl_len = label_lengths.data.cpu().numpy()\n",
    "#         output_batch = preds.permute(1, 0, 2)\n",
    "#         # out = output_batch.detach().cpu().numpy()\n",
    "#         out = output_batch.data.cpu().numpy()\n",
    "#         cer = torch.zeros(loss.shape)\n",
    "#         for j in range(out.shape[0]):\n",
    "#             logits = out[j, ...]\n",
    "#             pred, raw_pred = naive_decode(logits)\n",
    "#             pred_str = label2str(pred, self.idx_to_char, False)\n",
    "#             gt_str = label2str(lbl[index:lbl_len[j] + index], self.idx_to_char, False)\n",
    "#             index += lbl_len[j]\n",
    "#             cer[j] = error_rates.cer(gt_str, pred_str)\n",
    "#             # if self.verbose or psych[j] > 6000:\n",
    "#             #     print(psych[j])\n",
    "#         cer = Variable(cer, requires_grad = True).cuda()\n",
    "#         loss = loss + (psych * cer)\n",
    "#         return torch.sum(loss)\n",
    "\n",
    "\n",
    "# # config_path = sys.argv[1]\n",
    "# # try:\n",
    "# #     jobID = sys.argv[2]\n",
    "# # except:\n",
    "# #     jobID = \"\"\n",
    "# # print(jobID)\n",
    "\n",
    "# # with open(config_path) as f:\n",
    "# #     config = json.load(f)\n",
    "\n",
    "# # try:\n",
    "# #     model_save_path = sys.argv[3]\n",
    "# #     if model_save_path[-1] != os.path.sep:\n",
    "# #         model_save_path = model_save_path + os.path.sep\n",
    "# # except:\n",
    "\n",
    "# model_save_path = config['model_save_path']\n",
    "\n",
    "\n",
    "# verbose = False\n",
    "\n",
    "# dirname = os.path.dirname(model_save_path)\n",
    "# print(dirname)\n",
    "# if len(dirname) > 0 and not os.path.exists(dirname):\n",
    "#     os.makedirs(dirname)\n",
    "\n",
    "# # with open(config_path) as f:\n",
    "# #     paramList = f.readlines()\n",
    "\n",
    "# # for x in paramList:\n",
    "# #     print(x[:-1])\n",
    "\n",
    "# # baseMessage = \"\"\n",
    "\n",
    "# # for line in paramList:\n",
    "# #     baseMessage = baseMessage + line\n",
    "\n",
    "\n",
    "# # print(baseMessage)\n",
    "\n",
    "# idx_to_char, char_to_idx = load_char_set(config['character_set_path'])\n",
    "\n",
    "# train_dataset = HwDataset(config['training_set_path'], \n",
    "#                           char_to_idx, \n",
    "#                           img_height=config['network']['input_height'],\n",
    "#                           root_path=config['image_root_directory'], \n",
    "#                           augmentation=False, \n",
    "#                           psychPath=psychPath,\n",
    "#                           randomW=False)\n",
    "\n",
    "# try:\n",
    "#     test_dataset = HwDataset(config['validation_set_path'],\n",
    "#                              char_to_idx, \n",
    "#                              img_height=config['network']['input_height'], \n",
    "#                              root_path=config['image_root_directory'], \n",
    "#                              psychPath=psychPath)\n",
    "# except KeyError as e:\n",
    "#     print(\"No validation set found, generating one\")\n",
    "#     master = train_dataset\n",
    "#     print(\"Total of \" +str(len(master)) +\" Training Examples\")\n",
    "#     n = len(master)  # how many total elements you have\n",
    "#     n_test = int(n * .1)\n",
    "#     n_train = n - n_test\n",
    "#     idx = list(range(n))  # indices to all elements\n",
    "#     train_idx = idx[:n_train]\n",
    "#     test_idx = idx[n_train:]\n",
    "#     test_dataset = data.Subset(master, test_idx)\n",
    "#     train_dataset = data.Subset(master, train_idx)\n",
    "    \n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=1,\n",
    "#                               collate_fn=batch_collate)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=1,\n",
    "#                              collate_fn=batch_collate)\n",
    "# print(\"Train Dataset Length: \" + str(len(train_dataset)))\n",
    "# print(\"Test Dataset Length: \" + str(len(test_dataset)))\n",
    "\n",
    "\n",
    "# # if config['model'] == \"crnn\":\n",
    "# #     print(\"Using CRNN\")\n",
    "# #     hw = crnn.create_model({\n",
    "# #         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "# #         'num_of_channels': 3,\n",
    "# #         'num_of_outputs': len(idx_to_char) + 1\n",
    "# #     })\n",
    "# # if config['model'].upper() == \"UNET\":\n",
    "# #     print(\"Using UNET\")\n",
    "# #     hw = unet.create_model({\n",
    "# #         'input_height': config['network']['input_height'],\n",
    "# #         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "# #         'num_of_channels': 3,\n",
    "# #         'num_of_outputs': len(idx_to_char) + 1,\n",
    "# #         'bridge_width': config['network']['bridge_width']\n",
    "# #     })\n",
    "# # elif config['model'] == \"urnn\":\n",
    "# #     print(\"Using URNN\")\n",
    "# #     hw = urnn.create_model({\n",
    "# #         'input_height': config['network']['input_height'],\n",
    "# #         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "# #         'num_of_channels': 3,\n",
    "# #         'num_of_outputs': len(idx_to_char)+1,\n",
    "# #         'bridge_width': config['network']['bridge_width']\n",
    "# #     })\n",
    "# # elif config['model'] == \"urnn2\":\n",
    "# #     print(\"Using URNN with Curtis's recurrence\")\n",
    "# #     hw = urnn2.create_model({\n",
    "# #         'input_height': config['network']['input_height'],\n",
    "# #         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "# #         'num_of_channels': 3,\n",
    "# #         'num_of_outputs': len(idx_to_char) + 1,\n",
    "# #         'bridge_width': config['network']['bridge_width']\n",
    "# #     })\n",
    "# # elif config['model'] == \"crnn2\":\n",
    "# #     print(\"Using original CRNN\")\n",
    "# #     hw = crnn2.create_model({\n",
    "# #         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "# #         'num_of_channels': 3,\n",
    "# #         'num_of_outputs': len(idx_to_char) + 1\n",
    "# #     })\n",
    "# # elif config['model'] == \"urnn3\":\n",
    "# #     print(\"Using windowed URNN with Curtis's recurrence\")\n",
    "# #     hw = urnn_window.create_model({\n",
    "# #         'input_height': config['network']['input_height'],\n",
    "# #         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "# #         'num_of_channels': 3,\n",
    "# #         'num_of_outputs': len(idx_to_char) + 1,\n",
    "# #         'bridge_width': config['network']['bridge_width']\n",
    "# #     })\n",
    "\n",
    "\n",
    "# hw = create_model({\n",
    "#         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "#         'num_of_channels': 3,\n",
    "#         'num_of_outputs': len(idx_to_char) + 1\n",
    "#     })\n",
    "    \n",
    "# resume = True\n",
    "# try:\n",
    "#     config['model_load_path']\n",
    "# except KeyError:\n",
    "#     resume = False\n",
    "\n",
    "# pretrain = True\n",
    "# try:\n",
    "#     config['pretrained_load_path']\n",
    "# except KeyError:\n",
    "#     pretrain = False\n",
    "\n",
    "# freeze = True\n",
    "# try:\n",
    "#     config['freeze_pretrained_weights']\n",
    "# except KeyError:\n",
    "#     freeze = False\n",
    "\n",
    "# print(\"Freeze: \" + str(freeze))\n",
    "# metric = \"CER\"\n",
    "# try:\n",
    "#     metric = config['metric'].upper()\n",
    "# except KeyError:\n",
    "#     print(\"No metric listed, defaulting to Character Error Rate\")\n",
    "# print(\"Metric: \" + metric)\n",
    "\n",
    "\n",
    "\n",
    "# if resume:\n",
    "#     hw.load_state_dict(torch.load(config['model_load_path']))\n",
    "# elif pretrain:\n",
    "#     print(\"loading pretrained weights\")\n",
    "#     model_param = hw.state_dict()\n",
    "#     unet_param = torch.load(config['pretrained_load_path'])\n",
    "#     for i in unet_param.keys():\n",
    "#         model_param['UNet.' + i] = unet_param[i]\n",
    "#     hw.load_state_dict(model_param)\n",
    "\n",
    "# if freeze:\n",
    "#     for param in hw.UNet.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     hw.cuda()\n",
    "#     dtype = torch.cuda.FloatTensor\n",
    "#     print(\"Using GPU\")\n",
    "# else:\n",
    "#     dtype = torch.FloatTensor\n",
    "#     print(\"No GPU detected\")\n",
    "\n",
    "# optimizer = torch.optim.Adadelta(hw.parameters(), lr=config['network']['learning_rate'])\n",
    "# criterion = PsychCTC(idx_to_char, char_to_idx, verbose=False)\n",
    "# # criterion = CTCLoss(reduction='sum',zero_infinity=True)\n",
    "# lowest_loss = float('inf')\n",
    "# best_distance = 0\n",
    "# for epoch in range(1000):\n",
    "#     torch.enable_grad()\n",
    "#     startTime = time.time()\n",
    "#     message = \"foo\"\n",
    "#     sum_loss = 0.0\n",
    "#     sum_wer_loss = 0.0\n",
    "#     steps = 0.0\n",
    "#     hw.train()\n",
    "#     disp_ctc_loss = 0.0\n",
    "#     disp_loss = 0.0\n",
    "#     gt = \"\"\n",
    "#     ot = \"\"\n",
    "#     loss = 0.0\n",
    "#     # train_dataloader = torch.utils.data.random_split(train_dataloader, [16, len(train_dataloader) - 16])[0]\n",
    "#     print(\"Train Set Size = \" + str(len(train_dataloader)))\n",
    "#     prog_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "#     for i, x in prog_bar:\n",
    "#         # message = str(\"CER: \" + str(disp_loss) +\"\\nGT: \" +gt +\"\\nex: \"+out+\"\\nProgress\")\n",
    "#         prog_bar.set_description(f'CER: {disp_loss} CTC: {loss} Ground Truth: |{gt}| Network Output: |{ot}|')\n",
    "#         line_imgs = x['line_imgs']\n",
    "#         psych = Variable(torch.Tensor(x['psychs']).type(dtype), requires_grad=True)\n",
    "#         rem = line_imgs.shape[3] % 32\n",
    "#         if rem != 0:\n",
    "#             imgshape = line_imgs.shape\n",
    "#             temp = torch.zeros(imgshape[0], imgshape[1], imgshape[2], imgshape[3] + (32 - rem))\n",
    "#             temp[:, :, :, :imgshape[3]] = line_imgs\n",
    "#             line_imgs = temp\n",
    "#             del temp\n",
    "#         line_imgs = Variable(line_imgs.type(dtype), requires_grad=False)\n",
    "\n",
    "#         labels = Variable(x['labels'], requires_grad=False)\n",
    "#         label_lengths = Variable(x['label_lengths'], requires_grad=False)\n",
    "\n",
    "#         preds = hw(line_imgs).cpu()\n",
    "#         preds_size = Variable(torch.IntTensor([preds.size(1)] * preds.size(0)))\n",
    "\n",
    "#         print('pred size is ', preds_size.shape)\n",
    "        \n",
    "#         # output_batch = preds.permute(1,0,2)\n",
    "#         out = preds.data.cpu().numpy()\n",
    "#         preds = preds.permute(1, 0, 2)\n",
    "#         loss = criterion(preds, labels, preds_size, label_lengths, psych)\n",
    "#         # print(loss)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         # if i == 0:\n",
    "#         #    for i in range(out.shape[0]):\n",
    "#         #        pred, pred_raw = string_utils.naive_decode(out[i,...])\n",
    "#         #        pred_str = string_utils.label2str(pred_raw, idx_to_char, True)\n",
    "#         #        print(pred_str)\n",
    "\n",
    "#         for j in range(out.shape[0]):\n",
    "#             logits = out[j, ...]\n",
    "#             pred, raw_pred = string_utils.naive_decode(logits)\n",
    "#             pred_str = string_utils.label2str(pred, idx_to_char, False)\n",
    "#             gt_str = x['gt'][j]\n",
    "#             cer = error_rates.cer(gt_str, pred_str)\n",
    "#             wer = error_rates.wer(gt_str, pred_str)\n",
    "#             gt = gt_str\n",
    "#             ot = pred_str\n",
    "#             sum_loss += cer\n",
    "#             sum_wer_loss += wer\n",
    "#             steps += 1\n",
    "#         disp_loss = sum_loss / steps\n",
    "#     eTime = time.time() - startTime\n",
    "#     message = message + \"\\n\" + \"Epoch: \" + str(epoch) + \" Training CER: \" + str(\n",
    "#         sum_loss / steps) + \" Training WER: \" + str(sum_wer_loss / steps) + \"\\n\" + \"Time: \" + str(\n",
    "#         eTime) + \" Seconds\"\n",
    "#     print(\"Epoch: \" + str(epoch) + \" Training CER\", sum_loss / steps)\n",
    "#     print(\"Training WER: \" + str(sum_wer_loss / steps))\n",
    "#     print(\"Time: \" + str(eTime) + \" Seconds\")\n",
    "#     sum_loss = 0.0\n",
    "#     sum_wer_loss = 0.0\n",
    "#     steps = 0.0\n",
    "#     hw.eval()\n",
    "#     print(\"Validation Set Size = \" + str(len(test_dataloader)))\n",
    "#     for x in tqdm(test_dataloader):\n",
    "#         torch.no_grad()\n",
    "#         line_imgs = Variable(x['line_imgs'].type(dtype), requires_grad=False)\n",
    "#         # labels =  Variable(x['labels'], requires_grad=False, volatile=True)\n",
    "#         # label_lengths = Variable(x['label_lengths'], requires_grad=False, volatile=True)\n",
    "#         preds = hw(line_imgs).cpu()\n",
    "#         out = preds.data.cpu().numpy()\n",
    "#         for i, gt_line in enumerate(x['gt']):\n",
    "#             logits = out[i, ...]\n",
    "#             pred, raw_pred = string_utils.naive_decode(logits)\n",
    "#             pred_str = string_utils.label2str(pred, idx_to_char, False)\n",
    "#             cer = error_rates.cer(gt_line, pred_str)\n",
    "#             wer = error_rates.wer(gt_line, pred_str)\n",
    "#             sum_wer_loss += wer\n",
    "#             sum_loss += cer\n",
    "#             steps += 1\n",
    "\n",
    "#     message = message + \"\\nTest CER: \" + str(sum_loss / steps)\n",
    "#     message = message + \"\\nTest WER: \" + str(sum_wer_loss / steps)\n",
    "#     print(\"Test CER\", sum_loss / steps)\n",
    "#     print(\"Test WER\", sum_wer_loss / steps)\n",
    "#     best_distance += 1\n",
    "#     metric = \"CER\"\n",
    "#     if (metric == \"CER\"):\n",
    "#         if lowest_loss > sum_loss / steps:\n",
    "#             lowest_loss = sum_loss / steps\n",
    "#             print(\"Saving Best\")\n",
    "#             message = message + \"\\nBest Result :)\"\n",
    "#             torch.save(hw.state_dict(), os.path.join(model_save_path + str(epoch) + \".pt\"))\n",
    "#             best_distance = 0\n",
    "#         if best_distance > 800:\n",
    "#             break\n",
    "#     elif (metric == \"WER\"):\n",
    "#         if lowest_loss > sum_wer_loss / steps:\n",
    "#             lowest_loss = sum_wer_loss / steps\n",
    "#             print(\"Saving Best\")\n",
    "#             message = message + \"\\nBest Result :)\"\n",
    "#             torch.save(hw.state_dict(), os.path.join(model_save_path + str(epoch) + \".pt\"))\n",
    "#             best_distance = 0\n",
    "#         if best_distance > 80:\n",
    "#             break\n",
    "#     else:\n",
    "#         print(\"This is actually very bad\")ort json\n",
    "# imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da8cd34f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 6161\n",
      "Test Dataset Length: 966\n",
      "Freeze: False\n",
      "No metric listed, defaulting to Character Error Rate\n",
      "Metric: CER\n",
      "Using GPU\n",
      "Train Set Size = 771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CER: 0.0 CTC: 0.0 Ground Truth: || Network Output: ||:   0%|                                                           | 0/771 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape torch.Size([8, 295])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input_lengths must be of size batch_size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/575166.1.gpu/ipykernel_2625110/3356154414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsych\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;31m# print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/generic_model_search/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/575166.1.gpu/ipykernel_2625110/3356154414.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, preds, labels, preds_size, label_lengths, psych)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsych\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# print(len(self.char_to_idx))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mciterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# lbl = labels.detach().cpu().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/generic_model_search/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/generic_model_search/env/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, log_probs, targets, input_lengths, target_lengths)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,\n\u001b[0;32m-> 1744\u001b[0;31m                           self.zero_infinity)\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[0;31m# TODO: L1HingeEmbeddingCriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/generic_model_search/env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mctc_loss\u001b[0;34m(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)\u001b[0m\n\u001b[1;32m   2598\u001b[0m         )\n\u001b[1;32m   2599\u001b[0m     return torch.ctc_loss(\n\u001b[0;32m-> 2600\u001b[0;31m         \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_infinity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2601\u001b[0m     )\n\u001b[1;32m   2602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input_lengths must be of size batch_size"
     ]
    }
   ],
   "source": [
    "# sam's new main here \n",
    "\n",
    "import json\n",
    "# import character_set\n",
    "import sys\n",
    "# import hwpsych_dataset\n",
    "# from hwpsych_dataset import HwDataset\n",
    "# import model.urnn, urnn2, urnn_window\n",
    "# import model.crnn_5 as crnn\n",
    "# import crnn2\n",
    "import os\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "# import error_rates\n",
    "# import string_utils\n",
    "import time\n",
    "from torch.nn.modules.loss import CTCLoss\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "psychPath = \"./data\"\n",
    "\n",
    "class PsychCTC(torch.nn.Module):\n",
    "    def __init__(self, idx_to_char, char_to_idx, verbose=False):\n",
    "        super(PsychCTC, self).__init__()\n",
    "        self.citerion = CTCLoss(reduction='none', zero_infinity=True)\n",
    "        self.idx_to_char = idx_to_char\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(self, preds, labels, preds_size, label_lengths, psych):\n",
    "        # print(len(self.char_to_idx))\n",
    "        loss = self.citerion(preds, labels, preds_size, label_lengths).cuda()\n",
    "        index = 0\n",
    "        # lbl = labels.detach().cpu().numpy()\n",
    "        lbl = labels.data.cpu().numpy()\n",
    "        lbl_len = label_lengths.data.cpu().numpy()\n",
    "        output_batch = preds.permute(1, 0, 2)\n",
    "        # out = output_batch.detach().cpu().numpy()\n",
    "        out = output_batch.data.cpu().numpy()\n",
    "        cer = torch.zeros(loss.shape)\n",
    "        for j in range(out.shape[0]):\n",
    "            logits = out[j, ...]\n",
    "            pred, raw_pred = naive_decode(logits)\n",
    "            pred_str = label2str(pred, self.idx_to_char, False)\n",
    "            gt_str = label2str(lbl[index:lbl_len[j] + index], self.idx_to_char, False)\n",
    "            index += lbl_len[j]\n",
    "            # tensor object is not callable? \n",
    "            \n",
    "            \n",
    "#             print(type(gt_str))\n",
    "#             print(type(pred_str))\n",
    "            cer[j] = error_cer(gt_str, pred_str)\n",
    "            # if self.verbose or psych[j] > 0:\n",
    "            #     print(psych[j])\n",
    "        cer = Variable(cer, requires_grad=True).cuda()\n",
    "        loss = loss + (psych * cer)\n",
    "        return torch.sum(loss)\n",
    "\n",
    "\n",
    "# config_path = sys.argv[1]\n",
    "# try:\n",
    "#     jobID = sys.argv[2]\n",
    "# except:\n",
    "#     jobID = \"\"\n",
    "# print(jobID)\n",
    "\n",
    "# with open(config_path) as f:\n",
    "#     config = json.load(f)\n",
    "\n",
    "\n",
    "model_save_path = config['model_save_path']\n",
    "\n",
    "\n",
    "verbose = False\n",
    "\n",
    "dirname = os.path.dirname(model_save_path)\n",
    "\n",
    "# print(dirname)\n",
    "# if len(dirname) > 0 and not os.path.exists(dirname):\n",
    "#     os.makedirs(dirname)\n",
    "\n",
    "# with open(config_path) as f:\n",
    "#     paramList = f.readlines()\n",
    "\n",
    "# for x in paramList:\n",
    "#     print(x[:-1])\n",
    "\n",
    "baseMessage = \"foo\"\n",
    "\n",
    "# for line in paramList:\n",
    "#     baseMessage = baseMessage + line\n",
    "\n",
    "# print(baseMessage)\n",
    "\n",
    "idx_to_char, char_to_idx = load_char_set(config['character_set_path'])\n",
    "\n",
    "train_dataset = HwDataset(config['training_set_path'], \n",
    "                          char_to_idx, \n",
    "                          img_height=config['network']['input_height'],\n",
    "                          root_path=config['image_root_directory'],\n",
    "                          augmentation=False,\n",
    "                          psychPath=psychPath,\n",
    "                          randomW=False)\n",
    "\n",
    "try:\n",
    "    test_dataset = HwDataset(config['validation_set_path'], \n",
    "                             char_to_idx,\n",
    "                             img_height=config['network']['input_height'], \n",
    "                             root_path=config['image_root_directory'],\n",
    "                             augmentation=False, \n",
    "                             psychPath=psychPath, \n",
    "                             randomW=False)\n",
    "\n",
    "except KeyError as e:\n",
    "    print(\"No validation set found, generating one\")\n",
    "    master = train_dataset\n",
    "    print(\"Total of \" + str(len(master)) + \" Training Examples\")\n",
    "    n = len(master)  # how many total elements you have\n",
    "    n_test = int(n * .1)\n",
    "    n_train = n - n_test\n",
    "    idx = list(range(n))  # indices to all elements\n",
    "    train_idx = idx[:n_train]\n",
    "    test_idx = idx[n_train:]\n",
    "    test_dataset = data.Subset(master, test_idx)\n",
    "    train_dataset = data.Subset(master, train_idx)\n",
    "    \n",
    "    \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0,\n",
    "                              collate_fn=batch_collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=0,\n",
    "                             collate_fn=batch_collate)\n",
    "print(\"Train Dataset Length: \" + str(len(train_dataset)))\n",
    "print(\"Test Dataset Length: \" + str(len(test_dataset)))\n",
    "\n",
    "\n",
    "hw = torchvision.models.resnet50(pretrained=True)\n",
    "hw.fc = nn.Linear(2048,295)\n",
    "# hw = create_model({\n",
    "#         'input_height': config['network']['input_height'],\n",
    "#         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "#         'num_of_channels': 3,\n",
    "#         'num_of_outputs': len(idx_to_char) + 1\n",
    "#     })\n",
    "\n",
    "\n",
    "\n",
    "# if config['model'] == \"crnn\":\n",
    "#     print(\"Using CRNN\")\n",
    "#     hw = crnn.create_model({\n",
    "#         'input_height': config['network']['input_height'],\n",
    "#         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "#         'num_of_channels': 3,\n",
    "#         'num_of_outputs': len(idx_to_char) + 1\n",
    "#     })\n",
    "# elif config['model'] == \"urnn\":\n",
    "#     print(\"Using URNN\")\n",
    "#     hw = urnn.create_model({\n",
    "#         'input_height': config['network']['input_height'],\n",
    "#         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "#         'num_of_channels': 3,\n",
    "#         'num_of_outputs': len(idx_to_char) + 1,\n",
    "#         'bridge_width': config['network']['bridge_width']\n",
    "#     })\n",
    "# elif config['model'] == \"urnn2\":\n",
    "#     print(\"Using URNN with Curtis's recurrence\")\n",
    "#     hw = urnn2.create_model({\n",
    "#         'input_height': config['network']['input_height'],\n",
    "#         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "#         'num_of_channels': 3,\n",
    "#         'num_of_outputs': len(idx_to_char) + 1,\n",
    "#         'bridge_width': config['network']['bridge_width']\n",
    "#     })\n",
    "# elif config['model'] == \"crnn2\":\n",
    "#     print(\"Using original CRNN\")\n",
    "#     hw = crnn2.create_model({\n",
    "#         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "#         'num_of_channels': 3,\n",
    "#         'num_of_outputs': len(idx_to_char) + 1\n",
    "#     })\n",
    "# elif config['model'] == \"urnn3\":\n",
    "#     print(\"Using windowed URNN with Curtis's recurrence\")\n",
    "#     hw = urnn_window.create_model({\n",
    "#         'input_height': config['network']['input_height'],\n",
    "#         'cnn_out_size': config['network']['cnn_out_size'],\n",
    "#         'num_of_channels': 3,\n",
    "#         'num_of_outputs': len(idx_to_char) + 1,\n",
    "#         'bridge_width': config['network']['bridge_width']\n",
    "#     })\n",
    "\n",
    "resume = True\n",
    "try:\n",
    "    config['model_load_path']\n",
    "except KeyError:\n",
    "    resume = False\n",
    "\n",
    "pretrain = True\n",
    "try:\n",
    "    config['pretrained_load_path']\n",
    "except KeyError:\n",
    "    pretrain = False\n",
    "\n",
    "freeze = True\n",
    "try:\n",
    "    config['freeze_pretrained_weights']\n",
    "except KeyError:\n",
    "    freeze = False\n",
    "\n",
    "print(\"Freeze: \" + str(freeze))\n",
    "metric = \"CER\"\n",
    "try:\n",
    "    metric = config['metric'].upper()\n",
    "except KeyError:\n",
    "    print(\"No metric listed, defaulting to Character Error Rate\")\n",
    "print(\"Metric: \" + metric)\n",
    "\n",
    "if resume:\n",
    "    hw.load_state_dict(torch.load(config['model_load_path']))\n",
    "elif pretrain:\n",
    "    print(\"loading pretrained weights\")\n",
    "    model_param = hw.state_dict()\n",
    "    unet_param = torch.load(config['pretrained_load_path'])\n",
    "    for i in unet_param.keys():\n",
    "        model_param['UNet.' + i] = unet_param[i]\n",
    "    hw.load_state_dict(model_param)\n",
    "\n",
    "if freeze:\n",
    "    for param in hw.UNet.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    hw.cuda()\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    print(\"No GPU detected\")\n",
    "\n",
    "#optimizer = torch.optim.Adadelta(hw.parameters(), lr=config['network']['learning_rate'])\n",
    "optimizer = torch.optim.RMSprop(hw.parameters(), lr=config['network']['learning_rate'])\n",
    "lmbda = lambda epoch : 0.6\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lmbda)\n",
    "criterion = PsychCTC(idx_to_char, char_to_idx, verbose=True)\n",
    "criterion2 = CTCLoss(reduction='sum',zero_infinity=True)\n",
    "lowest_loss = float('inf')\n",
    "best_distance = 0\n",
    "last_drop = 1\n",
    "for epoch in range(100000):\n",
    "    torch.enable_grad()\n",
    "    startTime = time.time()\n",
    "    message = baseMessage\n",
    "    sum_loss = 0.0\n",
    "    sum_wer_loss = 0.0\n",
    "    steps = 0.0\n",
    "    hw.train()\n",
    "    disp_ctc_loss = 0.0\n",
    "    disp_loss = 0.0\n",
    "    gt = \"\"\n",
    "    ot = \"\"\n",
    "    loss = 0.0\n",
    "    # train_dataloader = torch.utils.data.random_split(train_dataloader, [16, len(train_dataloader) - 16])[0]\n",
    "    print(\"Train Set Size = \" + str(len(train_dataloader)))\n",
    "    prog_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "    for i, x in prog_bar:\n",
    "        # message = str(\"CER: \" + str(disp_loss) +\"\\nGT: \" +gt +\"\\nex: \"+out+\"\\nProgress\")\n",
    "        prog_bar.set_description(f'CER: {disp_loss} CTC: {loss} Ground Truth: |{gt}| Network Output: |{ot}|')\n",
    "        line_imgs = x['line_imgs']\n",
    "        psych = Variable(torch.Tensor(x['psychs']).type(dtype), requires_grad=True)\n",
    "        rem = line_imgs.shape[3] % 32\n",
    "        if rem != 0:\n",
    "            imgshape = line_imgs.shape\n",
    "            temp = torch.zeros(imgshape[0], imgshape[1], imgshape[2], imgshape[3] + (32 - rem))\n",
    "            temp[:, :, :, :imgshape[3]] = line_imgs\n",
    "            line_imgs = temp\n",
    "            del temp\n",
    "        line_imgs = Variable(line_imgs.type(dtype), requires_grad=False)\n",
    "\n",
    "        labels = Variable(x['labels'], requires_grad=False)\n",
    "        label_lengths = Variable(x['label_lengths'], requires_grad=False)\n",
    "        optimizer.zero_grad()\n",
    "        preds = hw(line_imgs).cpu()\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * preds.size(1)))\n",
    "\n",
    "        print('preds shape', preds.shape)\n",
    "        \n",
    "#         output_batch = preds.permute(1, 0, 2)\n",
    "        output_batch = preds\n",
    "\n",
    "        out = output_batch.data.cpu().numpy()\n",
    "        \n",
    "        loss = criterion(preds, labels, preds_size, label_lengths, psych)\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(hw.parameters(), 50)\n",
    "        optimizer.step()\n",
    "        # if i == 0:\n",
    "        #    for i in xrange(out.shape[0]):\n",
    "        #        pred, pred_raw = string_utils.naive_decode(out[i,...])\n",
    "        #        pred_str = string_utils.label2str(pred_raw, idx_to_char, True)\n",
    "        #        print(pred_str)\n",
    "\n",
    "        for j in range(out.shape[0]):\n",
    "            logits = out[j, ...]\n",
    "            pred, raw_pred = naive_decode(logits)\n",
    "            pred_str = label2str(pred, idx_to_char, False)\n",
    "            gt_str = x['gt'][j]\n",
    "            cer = error_cer(gt_str, pred_str)\n",
    "            wer = error_wer(gt_str, pred_str)\n",
    "            gt = gt_str\n",
    "            ot = pred_str\n",
    "            sum_loss += cer\n",
    "            sum_wer_loss += wer\n",
    "            steps += 1\n",
    "        disp_loss = sum_loss / steps\n",
    "    eTime = time.time() - startTime\n",
    "    message = message + \"\\n\" + \"Epoch: \" + str(epoch) + \" Training CER: \" + str(\n",
    "        sum_loss / steps) + \" Training WER: \" + str(sum_wer_loss / steps) + \"\\n\" + \"Time: \" + str(\n",
    "        eTime) + \" Seconds\"\n",
    "    print(\"Epoch: \" + str(epoch) + \" Training CER\", sum_loss / steps)\n",
    "    print(\"Training WER: \" + str(sum_wer_loss / steps))\n",
    "    print(\"Time: \" + str(eTime) + \" Seconds\")\n",
    "    sum_loss = 0.0\n",
    "    sum_wer_loss = 0.0\n",
    "    sum_ctc_loss = 0.0\n",
    "    steps = 0.0\n",
    "    hw.eval()\n",
    "    print(\"Validation Set Size = \" + str(len(test_dataloader)))\n",
    "    for x in tqdm(test_dataloader):\n",
    "        torch.no_grad()\n",
    "        line_imgs = Variable(x['line_imgs'].type(dtype), requires_grad=False)\n",
    "        labels =  Variable(x['labels'], requires_grad=False, volatile=True)\n",
    "        label_lengths = Variable(x['label_lengths'], requires_grad=False, volatile=True)\n",
    "        psych = Variable(torch.Tensor(x['psychs']).type(dtype), requires_grad=False)\n",
    "        preds = hw(line_imgs).cpu()\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * preds.size(1)))\n",
    "        print(\"--------------\")\n",
    "        print(preds.shape)\n",
    "        print(psych)\n",
    "        ctc = criterion2(preds, labels, preds_size, label_lengths).cpu().detach()\n",
    "        output_batch = preds.permute(1, 0, 2)\n",
    "        out = output_batch.data.cpu().numpy()\n",
    "        for i, gt_line in enumerate(x['gt']):\n",
    "            logits = out[i, ...]\n",
    "            pred, raw_pred = naive_decode(logits)\n",
    "            pred_str = label2str(pred, idx_to_char, False)\n",
    "            cer = error_cer(gt_line, pred_str)\n",
    "            wer = error_wer(gt_line, pred_str)\n",
    "            sum_wer_loss += wer\n",
    "            sum_loss += cer\n",
    "            sum_ctc_loss += ctc\n",
    "            steps += 1\n",
    "    message = message + \"\\nTest CTC: \" + str(sum_ctc_loss.numpy() / steps)\n",
    "    message = message + \"\\nTest CER: \" + str(sum_loss / steps)\n",
    "    message = message + \"\\nTest WER: \" + str(sum_wer_loss / steps)\n",
    "    print(\"Test CER\", sum_loss / steps)\n",
    "    print(\"Test WER\", sum_wer_loss / steps)\n",
    "    print(\"Test CTC\", sum_ctc_loss.numpy() / steps)\n",
    "    best_distance += 1\n",
    "    metric = \"CER\"\n",
    "    if (metric == \"CER\"):\n",
    "        if lowest_loss > sum_loss / steps:\n",
    "            lowest_loss = sum_loss / steps\n",
    "            print(\"Saving Best\")\n",
    "            message = message + \"\\nBest Result :)\"\n",
    "            torch.save(hw.state_dict(), os.path.join(model_save_path + str(epoch) + \".pt\"))\n",
    "#             email_update(message, jobID)\n",
    "            best_distance = 0\n",
    "            last_drop = 1\n",
    "        if best_distance/15 > last_drop:\n",
    "            last_drop+=1\n",
    "            scheduler.step()\n",
    "        if best_distance > 80:\n",
    "            break\n",
    "    elif (metric == \"WER\"):\n",
    "        if lowest_loss > sum_wer_loss / steps:\n",
    "            lowest_loss = sum_wer_loss / steps\n",
    "            print(\"Saving Best\")\n",
    "            message = message + \"\\nBest Result :)\"\n",
    "            torch.save(hw.state_dict(), os.path.join(model_save_path + str(epoch) + \".pt\"))\n",
    "#             email_update(message, jobID)\n",
    "            best_distance = 0\n",
    "            last_drop = 1\n",
    "        if best_distance/15 > last_drop:\n",
    "            last_drop+=1\n",
    "            scheduler.step()\n",
    "        if best_distance > 80:\n",
    "            break\n",
    "    elif (metric == \"CTC\"):\n",
    "        if lowest_loss > sum_ctc_loss / steps:\n",
    "            lowest_loss = sum_ctc_loss / steps\n",
    "            print(\"Saving Best\")\n",
    "            message = message + \"\\nBest Result :)\"\n",
    "            torch.save(hw.state_dict(), os.path.join(model_save_path + str(epoch) + \".pt\"))\n",
    "#             email_update(message, jobID)\n",
    "            best_distance = 0\n",
    "            last_drop = 1\n",
    "        if best_distance/15 > last_drop:\n",
    "            last_drop+=1\n",
    "            scheduler.step()\n",
    "        if best_distance > 80:\n",
    "            break\n",
    "    else:\n",
    "        print(\"This is actually very bad\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84fb6dcd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
